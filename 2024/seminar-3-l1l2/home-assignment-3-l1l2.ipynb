{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1/L2 регуляризация \n",
    "-----\n",
    "1. У нас есть данные ввиде множества пар $X$ и $y$: $\\{(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\}$\n",
    "2. Мы хотим найти такую функцию $\\hat{f}(x)$ которая бы минимизировала \n",
    "$$\n",
    "MSE(\\hat{f}, x) = \\frac{1}{N} \\sum_{i=1}^{N}\\left(\\ y_i - \\hat{f}(x_i, \\theta)\\ \\right) ^ 2 \\rightarrow \\text{min}_{\\theta}\n",
    "$$\n",
    "3. Мы будем искать $\\hat{f}(x)$ в предположении что это линейная функция:\n",
    "$$\n",
    "\\hat{f}(x, \\theta) = \\theta_0 + x^{[1]}\\theta_1 + x^{[2]}\\theta_2 + \\ldots + x^{[m]}\\theta_m\n",
    "$$\n",
    "\n",
    "**Вопрос**:\n",
    "\n",
    "Как запретить коэффициентам $\\theta$ быть большими?\n",
    "\n",
    "**Ответ**:\n",
    "\n",
    "Возьмем и добавим их в оптимизируемую функцию, т.к. мы ищем минимиум этой функции то в процессе оптимизации \n",
    "они будут (по-крайней мере мы на это надеемся) уменьшаться:\n",
    "\n",
    "\n",
    "$$\n",
    "MSE_{l_1}(\\hat{f}, x) = \\frac{1}{N} \\sum_{i=1}^{N}\\left(\\ y_i - \\hat{f}(x_i, \\theta)\\ \\right) ^ 2 + \\alpha \\sum_{j=1}^m |\\theta_j| \\rightarrow \\text{min}\n",
    "$$\n",
    "\n",
    "$$\n",
    "MSE_{l_2}(\\hat{f}, x) = \\frac{1}{N} \\sum_{i=1}^{N}\\left(\\ y_i - \\hat{f}(x_i, \\theta)\\ \\right) ^ 2 + \\alpha \\sum_{j=1}^m \\theta_j^2 \\rightarrow \\text{min}\n",
    "$$\n",
    "\n",
    "\n",
    "Обратите внимание что в сумме по тетта  индексация начинается с 1, а не с 0. Поскольку свободный коэффициент $\\theta_0$ **нет смысла регуляризовывать** — если мы будем штрафовать за его величину, то получится, что мы учитываем некие априорные представления о близости целевой переменной к нулю и отсутствии необходимости в учёте её смещения. \n",
    "\n",
    "Коэффициент $\\alpha$ называется **параметром регуляризации** и контролирует баланс\n",
    "между подгонкой под обучающую выборку и штрафом за излишнюю сложность, этот параметр **подбирается на кросс-валидации**.\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "-----\n",
    "\n",
    "Обе модели реализованы в sklearn в модуле linear_models:\n",
    "\n",
    "sklearn.linear_models.Lasso $\\rightarrow l_1$\n",
    "\n",
    "sklearn.linear_models.Ridge $\\rightarrow l_2$\n",
    "\n",
    "Давайте посмотрим как это выглядит на практике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, SGDRegressor, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_samples':2000,\n",
    "    'n_features':9,\n",
    "    'n_informative':5,\n",
    "    'bias':10,\n",
    "    'noise':5,\n",
    "    'coef':True, \n",
    "    'random_state': 51\n",
    "}\n",
    "\n",
    "\n",
    "X, y, _coef = make_regression(**params)\n",
    "\n",
    "\n",
    "# Загляните внутрь функции make_regression, что означает каждый параметр?\n",
    "# курсор внутрь круглых скобок и нажать shift+TAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Истинные коэффициенты модели:\\n', np.round(_coef, 3), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Lasso регуляризация\n",
    "\n",
    "1. Создайте объект класса Lasso с параметрами:\n",
    "    - `alpha=50`\n",
    "    - `fit-intercept=True`\n",
    "    - `random_state=33`\n",
    "2. Обучите модель Лассо регресии на данных X: `model.fit(X, y)`\n",
    "3. Предскажите с помощью этой модели значения целевой переменной: `model.predict(X)`\n",
    "4. Посчитайте MSE между предсказанным и истинным значением.\n",
    "5. Напечатайте веса обученной линейной модели. Что вы можете о них сказать?\n",
    "6. Используя параметр `alpha=15, 5, 2, 1, 0.3, 0.1, 0.03` обучите модель Lasso и посторойте зависимость **нормы** вектора весов $\\theta$ от величины `alpha`. Прокомментируйте полученный результат\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Ridge регуляризация\n",
    "\n",
    "1. Тоже но для Ridge регрессии\n",
    "2. Прокомментируйте различия между Ridge и Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Давайте посмотрим что происходит с весами модели, в процессе обучения градиентным спуском Лассо регрессии\n",
    "\n",
    "1. Попробуйте уменьшить значение параметра (например 0.01, 0.003, 0.0001) `eta0` отвечающего за learning rate, как изменились графики измениня коэффициентов линейной модели во время обучения?\n",
    "2. Следует ли регуляризовывать свободный член регресси (intercept), почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_params = {\n",
    "    'loss':'squared_error',\n",
    "    'penalty':'l1',\n",
    "    'alpha':.1,\n",
    "    'l1_ratio':1,\n",
    "    'fit_intercept':True,\n",
    "    'max_iter':None, \n",
    "    'shuffle':True,\n",
    "    'random_state':76,\n",
    "    'eta0' : 0.05,\n",
    "    'learning_rate':'constant',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = []\n",
    "intercept = []\n",
    "\n",
    "for m_iter in range(1, 20, 1):\n",
    "    \n",
    "    sgd_params['max_iter'] = m_iter\n",
    "    model = SGDRegressor(**sgd_params)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    coef.append(model.coef_)\n",
    "    intercept.append(model.intercept_)\n",
    "    \n",
    "coef = np.array(coef)\n",
    "intercept = np.array(intercept)\n",
    "print(model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "for n in range(1, 10):\n",
    "    ax = plt.subplot(int('34{}'.format(n)))\n",
    "    ax.plot(list(range(1, 20, 1)), coef[:, n-1])\n",
    "    ax.set_xticks(range(1, 20, 2))\n",
    "    ax.set_title(f'Coef {n}')\n",
    "    \n",
    "ax = plt.subplot(3,4,10)\n",
    "ax.plot(list(range(1, 20, 1)), intercept)\n",
    "ax.set_xticks(range(1, 20, 2))\n",
    "ax.set_title(f'Intercept')\n",
    "\n",
    "ax = plt.subplot(3,4,11)\n",
    "ax.plot(list(range(1, 20, 1)), np.abs(coef).sum(axis=1))\n",
    "ax.set_xticks(range(1, 20, 2))\n",
    "ax.set_title('$||w||_{l_1}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. \"Предсказание\" числа в другой системе исчисления\n",
    "\n",
    "Построим линейную модель которая переводит числа из *двоичной* системы исчисления в *десятичную*. Для этого сгенерируйте тренировочную выборку размера 10000 наблюдений, в которой в качестве признаков выступают бинарные векторы длины 32, а в качестве `y` значение в десятичной системе исчисления. Например:\n",
    "\n",
    "- $x_1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]$, $y_1 = 0$\n",
    "- $x_2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0]$, $y_2 = 525856$\n",
    "- $x_2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]$, $y_3 = 3$\n",
    "\n",
    "\n",
    "1. Обучите 3 линейные модели на **всех наблюдениях**: Линейная регрессия, Лассо регрессия, Гребневая регрессия (для всех моделей устновите параметр `fit_intercept=False`, что контролирует этот параметр?).\n",
    "2. Сравните ошибку, например MSE для всех трех моделей.\n",
    "3. Сравните коэффиценты обученных моделей, что вы можете о них сказать?\n",
    "4. Разделите ваши данные на тренировочную и тестовую выборки, обучите модели на тренировочной части данных, сделайте предсказание на тестовой. Сравните коэффициенты обученных моделей, сравните качество (в терминах MSE) на тестовой и тренировочной выборках.\n",
    "5. **Прокомментируйте полученные результаты**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "jupyter notebook c вашим решением необходимо отправить на почту kurmukovai@gmail.com, с темой письма [iitp-intro-ds-2024-ha3-Surname], например [iitp-intro-ds-2024-ha3-Kurmukov] до 11:59:59 МСК 22.02.2024.\n",
    "\n",
    "- Назовите ваш нотбук так же как и тему письма\n",
    "- Ваш нотбук должен исполняться по Kernel -> Restart & Run all без падений и ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
