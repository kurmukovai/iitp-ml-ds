{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with NA values\n",
    "\n",
    "1. Impute with some statistical (reasonable) value.\n",
    "    - Statistic over feature. \n",
    "    > fill NA Age with mean Age\n",
    "    - Statistic over groupby feature. \n",
    "    > fill NA Age of Females with mean Age of Females\n",
    "2. Impute with anomalous value + creating indicator column (prefered for tree based methods).\n",
    "3. Other\n",
    "    - Leave them as is. \n",
    "    - Predict missing values based on other features (*typically* impractical).\n",
    "    - KNN based\n",
    "    - Drop (*typically* the worst option).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Shorney, Mr. Charles Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>374910</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Goldschmidt, Mr. George B</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17754</td>\n",
       "      <td>34.6542</td>\n",
       "      <td>A5</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenfield, Mr. William Bertram</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17759</td>\n",
       "      <td>63.3583</td>\n",
       "      <td>D10 D12</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Doling, Mrs. John T (Ada Julia Bone)</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>231919</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Kantor, Mr. Sinai</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>244367</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "..          ...       ...     ...   \n",
       "95           96         0       3   \n",
       "96           97         0       1   \n",
       "97           98         1       1   \n",
       "98           99         1       2   \n",
       "99          100         0       2   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                ...     ...   ...    ...   \n",
       "95                        Shorney, Mr. Charles Joseph    male   NaN      0   \n",
       "96                          Goldschmidt, Mr. George B    male  71.0      0   \n",
       "97                    Greenfield, Mr. William Bertram    male  23.0      0   \n",
       "98               Doling, Mrs. John T (Ada Julia Bone)  female  34.0      0   \n",
       "99                                  Kantor, Mr. Sinai    male  34.0      1   \n",
       "\n",
       "    Parch            Ticket     Fare    Cabin Embarked  \n",
       "0       0         A/5 21171   7.2500      NaN        S  \n",
       "1       0          PC 17599  71.2833      C85        C  \n",
       "2       0  STON/O2. 3101282   7.9250      NaN        S  \n",
       "3       0            113803  53.1000     C123        S  \n",
       "4       0            373450   8.0500      NaN        S  \n",
       "..    ...               ...      ...      ...      ...  \n",
       "95      0            374910   8.0500      NaN        S  \n",
       "96      0          PC 17754  34.6542       A5        C  \n",
       "97      1          PC 17759  63.3583  D10 D12        C  \n",
       "98      1            231919  23.0000      NaN        S  \n",
       "99      0            244367  26.0000      NaN        S  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/anvar/titanic.csv')\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, train_size=0.33, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Impute with different statistics.\n",
    "\n",
    "- Impute with some statistics of this particular feature:\n",
    "    - mean (average)\n",
    "    - median\n",
    "    - percentiles\n",
    "    - mode (most frequent). Also works for categorical features\n",
    "    \n",
    "- Impute with some statistics computed within categorical groups:\n",
    "    - Impute missing `Age` with average/median `Age` of a person of the same `Sex`\n",
    "    - Impute missing `Price` with the average/median Price of a item from the same `Category`\n",
    "    \n",
    "> Must be done with extreme **CAUTION**, otherwise easy to overfit.\n",
    "\n",
    "Imputation in **test** part of the data better be done based on statistics computed on **train**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.1 Statistic over the feature\n",
    "\n",
    "### Manual computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anvar/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "aver_age = df.Age.mean()\n",
    "\n",
    "df.Age = df.Age.fillna(aver_age)\n",
    "\n",
    "# Or if we have X_train, X_test\n",
    "\n",
    "aver_age = X_train.Age.mean()\n",
    "\n",
    "X_train.Age = X_train.Age.fillna(aver_age)\n",
    "X_test.Age = X_train.Age.fillna(aver_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.impute` to use with `sklearn.pipe.Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anvar/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/home/anvar/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "df.Age = imputer.fit_transform(df.Age.values.reshape(-1, 1))\n",
    "\n",
    "# Or if we have X_train, X_test\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(X_train.Age.values.reshape(-1, 1))\n",
    "\n",
    "X_train.Age = imputer.transform(X_train.Age.values.reshape(-1, 1))\n",
    "X_test.Age = imputer.transform(X_test.Age.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Statistics within groups\n",
    "\n",
    "### Manual computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aver_age_sex = df.groupby(['Sex'])['Age'].mean()\n",
    "\n",
    "df[df.Age.isna()].Age = df[df.Age.isna()].Sex.map(aver_age_sex)\n",
    "\n",
    "# Or if we have X_train, X_test\n",
    "\n",
    "aver_age_sex = X_train.groupby(['Sex'])['Age'].mean()\n",
    "\n",
    "X_train[X_train.Age.isna()].Age = X_train[X_train.Age.isna()].Sex.map(aver_age_sex)\n",
    "X_test[X_test.Age.isna()].Age = X_test[X_test.Age.isna()].Sex.map(aver_age_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.impute` to use with `sklearn.pipe.Pipeline`\n",
    "\n",
    "requires writing a custom Imputer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, groupby_col, impute_col, agg):\n",
    "        \"\"\"Imputes missing values using groupby aggregated statistic.\n",
    "        \n",
    "        Parameters\n",
    "        ---\n",
    "        \n",
    "        groupby_col - str,\n",
    "            column to groupby over\n",
    "            \n",
    "        impute_col - str,\n",
    "            column to make imputation\n",
    "            \n",
    "        agg - function,\n",
    "            aggregation function\n",
    "        \"\"\"\n",
    "        self.groupby_col = groupby_col\n",
    "        self.impute_col = impute_col\n",
    "        self.agg = agg\n",
    "        self._mapper = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self._mapper = X.groupby(self.groupby_col)[self.impute_col].apply(self.agg)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X.loc[:, self.impute_col] = X[self.groupby_col].map(self._mapper)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anvar/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "# Statistic over the feature\n",
    "\n",
    "imputer = CustomImputer(groupby_col='Sex', impute_col='Age', agg=np.mean)\n",
    "\n",
    "df.Age = imputer.fit_transform(df)\n",
    "\n",
    "# Or if we have X_train, X_test\n",
    "\n",
    "imputer = CustomImputer(groupby_col='Sex', impute_col='Age', agg=np.mean)\n",
    "\n",
    "imputer.fit(X_train)\n",
    "\n",
    "X_train.Age = imputer.transform(X_train)\n",
    "X_test.Age = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create indicator column.\n",
    "\n",
    "Sometimes (often) missing value of some feature is itself a great signal. \n",
    "> Recall, `Life Boat` in Titanic dataset, the fact that the person have a NA value in this column means that he is most probably did not survived (otherwise is also true, those who have non NA Life Boat are most likely survived).\n",
    "\n",
    "This approach is especially useful if you use tree based methods.\n",
    "\n",
    "1. Impute NA values with some anomalous, impossible value, e.g. negative value for `Age`.\n",
    "2. Create an additional indicator column, 1 if value is missing and 0 otherwise.\n",
    "\n",
    "Alternitevely, IF most of the values are missing, you could simply create indicator column (and drop the original column).\n",
    "\n",
    "> Easier cross-validation, since we could do this preprocessing before `train-test` split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indicator column\n",
    "\n",
    "df['has_NA_Age'] = df.Age.isna().astype(int)\n",
    "\n",
    "# Fill missing values with impossible value for this feature\n",
    "\n",
    "df.Age.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>has_NA_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex    Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male   22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female   26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35.0      1   \n",
       "4                             Allen, Mr. William Henry    male   35.0      0   \n",
       "..                                                 ...     ...    ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male   27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female   19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female -999.0      1   \n",
       "889                              Behr, Mr. Karl Howell    male   26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male   32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  has_NA_Age  \n",
       "0        0         A/5 21171   7.2500   NaN        S           0  \n",
       "1        0          PC 17599  71.2833   C85        C           0  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S           0  \n",
       "3        0            113803  53.1000  C123        S           0  \n",
       "4        0            373450   8.0500   NaN        S           0  \n",
       "..     ...               ...      ...   ...      ...         ...  \n",
       "886      0            211536  13.0000   NaN        S           0  \n",
       "887      0            112053  30.0000   B42        S           0  \n",
       "888      2        W./C. 6607  23.4500   NaN        S           1  \n",
       "889      0            111369  30.0000  C148        C           0  \n",
       "890      0            370376   7.7500   NaN        Q           0  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Other\n",
    "\n",
    "## 3.1 Do not deal with them.\n",
    "\n",
    "Some of the modern implementations (e.g. catboost) will handle missing values for you. \n",
    "Typically, using one of the methods above, e.g. catboost uses two approaches:\n",
    "- “Min” — Missing values are processed as the minimum value (less than all other values) for the feature. It is guaranteed that a split that separates missing values from all other values is considered when selecting trees.\n",
    "- “Max” — Missing values are processed as the maximum value (greater than all other values) for the feature. It is guaranteed that a split that separates missing values from all other values is considered when selecting trees.\n",
    "\n",
    "from  https://catboost.ai/docs/concepts/input-data_custom-borders.html\n",
    "\n",
    "Both are versions of the `2. Create indicator column.`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "¯\\_(ツ)_/¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Predict missing values based on other features (typically impractical)\n",
    "\n",
    "> The idea is to solve regression or classification problem but instead of original target variable use column with missing values. The problem is, it requires embedded cross-validation and goes far beyond this introductory course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Use similar observations (KNN)\n",
    "\n",
    "> Find k observations which has similar feature (and not NA in required column) representation and average over them.\n",
    "\n",
    "This option is similar to `1.2 Statistics within groups`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation\n",
      " [[ 1.  2. nan]\n",
      " [ 3.  4.  3.]\n",
      " [nan  6.  5.]\n",
      " [ 8.  8. nan]]\n",
      "\n",
      "After imputation\n",
      " [[1.  2.  4. ]\n",
      " [3.  4.  3. ]\n",
      " [5.5 6.  5. ]\n",
      " [8.  8.  4. ]]\n"
     ]
    }
   ],
   "source": [
    "# Example from sklearn documentation\n",
    "\n",
    "X = np.array([[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, np.nan]])\n",
    "print('Before imputation\\n', X)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "X = imputer.fit_transform(X)\n",
    "print('\\nAfter imputation\\n', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Drop missing values.\n",
    "\n",
    "Rarely a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NA\n",
    "\n",
    "df.Age.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with `any` NA\n",
    "\n",
    "df.dropna(inplace=True, axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "I would personally recommend to use `2. Indicator column` approach almost always (or methods wich works with NA out of the box), but under certain circumstances other methods might work better.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "1. Impute with some statistical (reasonable) value.\n",
    "    - Statistic over feature. \n",
    "    > fill NA Age with mean Age\n",
    "    - Statistic over groupby feature. \n",
    "    > fill NA Age of Females with mean Age of Females\n",
    "2. Impute with anomalous value + creating indicator column (prefered for tree based methods).\n",
    "3. Other\n",
    "    - Leave them as is. \n",
    "    - Predict missing values based on other features (*typically* impractical).\n",
    "    - KNN based\n",
    "    - Drop (*typically* the worst option).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
