{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f43bb357",
   "metadata": {},
   "source": [
    "# Решающее дерево для задачи регрессии\n",
    "\n",
    "\n",
    "Ваше домашнее задание состоит из 2 частей, задания 1-3 включают в себя имплементацию алгоритма Решающего дерева для задачи регрессии, в задании 4 необходимо применить метод решающего дерева к набору данных стоимости квартир.\n",
    "\n",
    "# 1. Починить имплементацию решающего дерева\n",
    "\n",
    "Ниже представлена наивная имплементация алгоритма Решающего дерева для задачи регрессии и пример запуска. В качестве критерия остановки выступает максимальная глубина дерева и минимальное количество наблюдений в листе.\n",
    "\n",
    "Вам необходимо внести несколько изменений:\n",
    "\n",
    "    1.1  Сейчас параметр `min_samples_leaf` не используется, таким образом в листах дерева может оказаться произвольное количество наблюдений, вам необходимо это починить.\n",
    "    1.2 Для удобства отслеживания числа наблюдений в каждом узле добавьте поле \"support\" (количество наблюдейний в текущем узле) в словарь `self.tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth, min_samples_leaf):\n",
    "        \"\"\"\n",
    "        max_depth, int - максимальная глубина дерева\n",
    "        min_samples_leaf, int - минимальное количество наблюдений в листе\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.tree = None\n",
    "        \n",
    "    def _split_data(self, X, y, feature_index, threshold):\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        right_mask = X[:, feature_index] > threshold\n",
    "        X_left, y_left = X[left_mask], y[left_mask]\n",
    "        X_right, y_right = X[right_mask], y[right_mask]\n",
    "        return X_left, y_left, X_right, y_right\n",
    "    \n",
    "    def _mse(self, y):\n",
    "        return np.mean((y - np.mean(y))**2)\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        best_feature_index, best_threshold = None, None\n",
    "        best_mse = float('inf')\n",
    "        n_features = X.shape[1]\n",
    "        for feature_index in range(n_features):\n",
    "            feature_values = X[:, feature_index]\n",
    "            thresholds = np.unique(feature_values)\n",
    "            for threshold in thresholds:\n",
    "                X_left, y_left, X_right, y_right = self._split_data(X, y, feature_index, threshold)\n",
    "                mse_left = self._mse(y_left)\n",
    "                mse_right = self._mse(y_right)\n",
    "                mse_split = (len(y_left) * mse_left + len(y_right) * mse_right) / len(y)\n",
    "                if mse_split < best_mse:\n",
    "                    best_mse = mse_split\n",
    "                    best_feature_index = feature_index\n",
    "                    best_threshold = threshold\n",
    "        return best_feature_index, best_threshold\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if depth == self.max_depth:\n",
    "            return np.mean(y)\n",
    "        feature_index, threshold = self._best_split(X, y)\n",
    "        if feature_index is None:\n",
    "            return np.mean(y)\n",
    "        X_left, y_left, X_right, y_right = self._split_data(X, y, feature_index, threshold)\n",
    "        tree = {\n",
    "            'feature_index': feature_index,\n",
    "            'threshold': threshold\n",
    "        }\n",
    "        tree['left'] = self._build_tree(X_left, y_left, depth + 1)\n",
    "        tree['right'] = self._build_tree(X_right, y_right, depth + 1)\n",
    "        return tree\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "    def _predict_one(self, tree, x):\n",
    "        if isinstance(tree, float):\n",
    "            return tree\n",
    "        feature_index, threshold = tree['feature_index'], tree['threshold']\n",
    "        if x[feature_index] <= threshold:\n",
    "            return self._predict_one(tree['left'], x)\n",
    "        else:\n",
    "            return self._predict_one(tree['right'], x)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            prediction = self._predict_one(self.tree, x)\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da72439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=3, min_samples_leaf=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3770af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(name=\"house_prices\", as_frame=True, return_X_y=True)\n",
    "X = X.dropna(axis=1)\n",
    "X = X.loc[:, X.dtypes == 'int64']\n",
    "X.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3071ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca4dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.predict(X.values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be899e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da3c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86f0a3f3",
   "metadata": {},
   "source": [
    "# 2. Воспользуйтесь `line_profiler` \n",
    "\n",
    "Текущая имплементация Решающего дерева работает очень медленно. Чтобы локализовать что отнимает так много времени воспользуйтесь `line_profiler`.\n",
    "\n",
    "    2.1 Что занимает больше всего времени на этапе обучения решающего дерева?\n",
    "    \n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d20345",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f dt._build_tree dt._build_tree(X.values[:100], y.values[:100], 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0d2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a77b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c739f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e11520fe",
   "metadata": {},
   "source": [
    "# 3. Гистограммы\n",
    "\n",
    "Вместо того чтобы перебирать все уникальные значения признака в методе `self._best_split` мы будем восстанавливать гистограмму распределения признака и перебирать только уникальные значения в бинах, см. пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(0, 1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_height, bins_edges = np.histogram(x, bins=10)\n",
    "bins_centers = (bins_edges[:-1]+bins_edges[1:])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd79f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bins_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ad4d9",
   "metadata": {},
   "source": [
    "Т.е. вместо \"200\" уникальных трешхолдов мы будем использовать только \"10\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324cba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ширина бинов одинакова\n",
    "bins_edges[:-1]-bins_edges[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2878eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(bins_centers, bins_height, width=0.6);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8fe75",
   "metadata": {},
   "source": [
    "### Выбор числа бинов\n",
    "\n",
    "Количество бинов гистограммы может сильно повлиять на то как вы приближаете ваше распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de2b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(12, 9))\n",
    "n_bins = np.round(np.linspace(1, 50, 12)).astype(int)\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax.hist(x, bins=n_bins[i])\n",
    "    ax.set_title(f'number of bins is {n_bins[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebba3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b2a962c",
   "metadata": {},
   "source": [
    "### Метод Freedman–Diaconis \n",
    "\n",
    "https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule\n",
    "\n",
    "Для выбора числа бинов в гистограмме воспользуйте правилом Freedman–Diaconis:\n",
    "\n",
    "$$\\text{Bin width} = 2 \\cdot \\frac{IQR(x)}{x^{1/3}}$$\n",
    "\n",
    "Где IQR это inter quartile range, то есть расстояние между 25 и 75 перцентилем распределения.\n",
    "\n",
    "    3.1 Метод Freedman–Diaconis дает формулу для ширины бина (одинаковая для всех бинов), а чему в таком случае равно число бинов?\n",
    "    3.2 Имплементируйте функцию для подсчета числа бинов по формуле Freedman–Diaconis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57681a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iqr\n",
    "np.quantile(x, 0.75) - np.quantile(x, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ff3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa125aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6eb6b26",
   "metadata": {},
   "source": [
    "### В методе `self._best_split` замените перебор всех уникальных трешхолдов на перебор только по уникальным бинам\n",
    "\n",
    "Количество бинов подбирайте методом Freedman–Diaconis\n",
    "\n",
    "    3.3 Засеките время обучения вашего регрессора до и после имплементации гистограмм, насколько быстрее стало обучение?\n",
    "    3.4 Сравните скорость работы вашей имплементации решающего дерева и имплементации sklearn.tree.DecisionTreeRegressor, с аналогичными гиперпараметрами\n",
    "    3.5 Опишите другие способы ускорения алгоритма решающего дерева (кроме приближения распределений признаков гистограмми)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e94e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c870f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be258550",
   "metadata": {},
   "source": [
    "# 4. House pricing\n",
    "\n",
    "воспользуйтесь набором данных из ДЗ2. Обучите алгоритм Решающего дерева (воспользуйтесь имплементацией из sklearn), не забудьте разделить данные на тренировочную и тестовую выборки. \n",
    "\n",
    "    4.1. Влияет ли нормировка признаков на алгоритм Решающего дерева? Почему?\n",
    "    4.2. Переберите различные значения гиперпараметров решающего дерева с использованием функции GridSearchCV, какое наилучшее качество в терминах mean_squared_error вам удалось получить? Насколько это лучше/хуже качества линейных моделей (на том же train-test разбиении).\n",
    "    4.3. Сравните важность признаков которую предлагает встроенный метод DecisionTreeRegressor().feature_importances_ с важностью признаков полученной для линейных моделей, прокомментируйте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6d450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d69f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12745cdf",
   "metadata": {},
   "source": [
    "jupyter notebook c вашим решением необходимо отправить на почту kurmukovai@gmail.com, с темой письма [iitp-intro-ds-2024-ha4-Surname], например [iitp-intro-ds-2024-ha4-Kurmukov] до 12:59:59 МСК 29.02.2024. Дополнительный балл за раннюю сдачу до 23:59:59 27.02.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e867c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
